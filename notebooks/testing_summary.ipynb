{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importaciones\n",
    "nota: estas importaciones son necesarias para este notebook, si quiere ver las importaciones necesarias para la función especifica vaya al archivo original [summary](../features/summary.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes y validaciones \n",
    "Estos son dataframes de testeo obtenidos de internet. \n",
    "Las validaciones son una pieza importante de la parte tecnica de la libreria. Para mas detalle vea las [validaciones](../validaciones/validaciones.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = spark.read.csv('csv/used_cars_data.csv' , header=True,inferSchema=True )\n",
    "df_countries = spark.read.csv('csv/countries.csv' ,header= True ,inferSchema=True )\n",
    "df_dates = spark.read.csv('csv/US_Holiday_Dates_(2004-2021).csv' , header=True,inferSchema=True )\n",
    "df_cop = spark.read.csv('csv/eurocup_2020_results.csv', header= True,inferSchema=True)\n",
    "df_test = spark.read.csv('csv/Countries_usefulFeatures.csv' , header= True ,inferSchema=True)\n",
    "df_ernigs = spark.read.csv('csv/all_earnings_dates.csv' , header= True ,inferSchema=True)\n",
    "df_null = spark.read.csv('csv/cars_null.csv' , header= True  ,inferSchema=True)\n",
    "df_seph = spark.read.csv('csv/sephora_website_dataset.csv', header= True,inferSchema=True)\n",
    "df_tw = spark.read.csv('csv/most_followed_twitter.csv' , header= True ,inferSchema=True)\n",
    "df_airlines = spark.read.csv('csv/airlines.csv' , header= True ,inferSchema=True)\n",
    "\n",
    "def is_dataframe(dataframe):\n",
    "    try:\n",
    "        type_df = type(dataframe)\n",
    "        if not isinstance(dataframe , DataFrame):\n",
    "            raise TypeError(f\"Expected a DataFrame, got {type_df}\")\n",
    "    except Exception as e: \n",
    "        print(\"An error occurred: \", e)\n",
    "def sel_num_cols(dataframe): \n",
    "    lista_columnas_numericas =  []\n",
    "    tipos_numericos = [LongType().simpleString(), DoubleType().simpleString(), \n",
    "        IntegerType().simpleString() , ShortType().simpleString() ,\n",
    "        FloatType().simpleString() , DecimalType().simpleString()]\n",
    "    for columnas, dtype in dataframe.dtypes:\n",
    "        if dtype in tipos_numericos: lista_columnas_numericas.append(columnas)\n",
    "    \n",
    "    return lista_columnas_numericas\n",
    "def df_has_numtype(dataframe):\n",
    "    try:\n",
    "        is_dataframe(dataframe)\n",
    "        tipos_numericos = [LongType().simpleString(), DoubleType().simpleString(), \n",
    "        IntegerType().simpleString() , ShortType().simpleString() ,\n",
    "        FloatType().simpleString() , DecimalType().simpleString()]\n",
    "        for _ , dtype in dataframe.dtypes: \n",
    "            if dtype in tipos_numericos:  return True \n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred: \", e)\n",
    "def df_has_null(dataframe): \n",
    "    try:    \n",
    "        is_dataframe(dataframe)\n",
    "        for col in dataframe.columns:\n",
    "            if dataframe.filter(isnull(col)).count() > 0 : return (True , col)\n",
    "        return (False , None)\n",
    "    except Exception as e: \n",
    "        print(\"An error occurred: \", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumary(dataframe ):\n",
    "    \"\"\"\n",
    "    Esta función recibe un dataframe de PySpark. \n",
    "    La función devuelve un dataframe con un resumen estadistico de todas las\n",
    "    columnas de tipo numericas, este resumen toma como base a la funcíon Summary()\n",
    "    de pyspark y le agrega la moda y antimoda al dataframe. En caso de que no haya \n",
    "    columnas tipo numericas la función no hara nada y retornara el mismo dataframe entregado.\n",
    "    \n",
    "    Argumento:\n",
    "    dataframe (pyspark.sql.dataframe.DataFrame): Dataframe que desea obtener datos estadisticos.\n",
    "    \n",
    "    Retorno:\n",
    "    dataframe (pyspark.sql.dataframe.DataFrame): Dataframe de PySpark con el resumen estadistico mejorado en caso de tener columnas de tipo numericas.\n",
    "    \"\"\"\n",
    "    is_dataframe(dataframe) \n",
    "    if df_has_numtype(dataframe):\n",
    "        num_cols = sel_num_cols(dataframe)\n",
    "        df_columns = dataframe.select(*num_cols)\n",
    "        lista_modas= ['moda']\n",
    "        lista_antimoda = ['antimoda']\n",
    "        lista_columnas = ['summary']\n",
    "        resultado , _  = df_has_null(dataframe)\n",
    "        mensaje = 'las columnas numericas tienen datos nulos' if resultado else 'columnas sin datos nulos'\n",
    "        print(mensaje)\n",
    "        for col in num_cols:\n",
    "            mode_val = dataframe.groupBy(col).count().sort('count', ascending=False).first()[0]\n",
    "            anti_mode_val = dataframe.groupBy(col).count().sort('count', ascending=True).first()[0]\n",
    "            lista_modas.append(mode_val)\n",
    "            lista_antimoda.append(anti_mode_val)\n",
    "        for valor in num_cols: lista_columnas.append(valor)\n",
    "        \n",
    "        lista_modas = tuple(lista_modas)\n",
    "        lista_antimoda = tuple(lista_antimoda)\n",
    "        new_row = spark.createDataFrame([lista_modas] , [*lista_columnas])\n",
    "        new_row_anti_mode = spark.createDataFrame([lista_antimoda] , [*lista_columnas])\n",
    "        df_columns.summary().unionAll(new_row).unionAll(new_row_anti_mode).show()\n",
    "        return df_columns.asummary().unionAll(new_row).unionAll(new_row_anti_mode)\n",
    "    else : \n",
    "        print('El dataframe pyspark propocionado no tiene numeros')\n",
    "        return dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo en databricks\n",
    "Este es un ejemplo de esta función ejecutada en databricks\n",
    "### dataframe instanciado\n",
    "![dataframe instanciado](../img/dataframe.png)\n",
    "### dataframe obtenido al aplicar la función\n",
    "![dataframe obtenido después de haber utilizado la función](../img/summary.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mas ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sumary1 = sumary(df_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sumary2 = sumary(df_airlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sumary3 = sumary(df_cop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sumary4 = sumary(df_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sumary5 = sumary(df_dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
